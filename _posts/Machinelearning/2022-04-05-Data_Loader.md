---
title : "âš™ 8. [íŒŒì´í† ì¹˜] Data_Loader"

categories:
    - Machinelearning
tags:
    - [AI, Regression, Prediction, Mini_Batch, Data_loader]

toc : true
toc_sticky : true
use_math : true

date: 2022-04-05
last_modified_at: 2022-04-05
---  
* * *  

ğŸ”¨ ì €ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” <a>dataloader</a>ë¥¼ ì§ì ‘ êµ¬í˜„í•´ í•™ìŠµì„ ì§„í–‰í–ˆë‹¤. í•˜ì§€ë§Œ ëª¨ë“  ë°ì´í„°ì— ëŒ€í•´ì„œ ê°ê°ì„ ë°”ê¿”ì£¼ê³  ì ìš©í•˜ëŠ” ê²Œ ì‰½ì§€ ì•Šê¸° ë•Œë¬¸ì— íŒŒì´í† ì¹˜ëŠ” ì´ë¥¼ ìœ„í•œ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.  

ğŸ”¨ Dataset, DataLoaderì— ëŒ€í•´ ì•Œì•„ë³´ì.  

* * *
## 1. CustomDataset / DataLoader

ğŸ”¨ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.  

```py
import torch
from torch.utils.data import Dataset, DataLoader
```  

ì—¬ê¸°ì— pandasë‚˜ numpy, ë‹¤ë¥¸ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¶”ê°€í•˜ë©´ ëœë‹¤.  

ì´ë ‡ê²Œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì™”ìœ¼ë©´ ì´ì   <a>CunstomDataset( )</a>ë¥¼ ì •ì˜í•´ë³´ì. ëŒ€ëµì ì¸ ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ë‹¤.  

```py
class CustomDataset(Dataset):
    def __init__(self):

        
    def __len__(self):
    

    def __getitem__(self, idx):
```  

- <b>__init__(self)</b>
    - í•„ìš”í•œ ë³€ìˆ˜ë“¤ì„ ì„ ì–¸í•˜ëŠ” ë©”ì„œë“œ. 
    - inputìœ¼ë¡œ ì˜¤ëŠ” xì™€ yë¥¼ load í•˜ê±°ë‚˜, íŒŒì¼ëª©ë¡ì„ loadí•œë‹¤.  

- <b>__len__(self)</b>
    - x, yì˜ ê¸¸ì´ë¥¼ ë„˜ê²¨ì£¼ëŠ” ë©”ì„œë“œ.  

- <b>__getitem__(self, index) </b>
    - indexë²ˆì§¸ ë°ì´í„°ë¥¼ return í•˜ëŠ” ë©”ì„œë“œ.  
  
ğŸ”¨ ì´ë ‡ê²Œ CustomDatasetì„ ì •ì˜í•˜ê³  ë‚œ ë’¤ì—ëŠ” ê·¸ëƒ¥ ì´ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ì €ë²ˆì— ì‚¬ìš©í•œ Covid_19 ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ì„œ train_setê³¼ labelì„ ì§ì ‘ ê°€ì ¸ì™€ë³´ì.  

* * *
## 2. ì½”ë“œ ì‘ì„± 

```py
import pandas as pd
import matplotlib.pyplot as plt
import torch
import numpy as np
import random
from torch.utils.data import Dataset, DataLoader

d = pd.read_excel('C:\\Users\mingu\Desktop\\2020_covid19_KR_seoul.xlsx')

y = d.iloc[7:,13].to_numpy()
X = d.iloc[:-7,[2,6,5,4,7,8,3,12]].to_numpy()

X = torch.tensor(X).type(torch.FloatTensor)
y = torch.tensor(y).type(torch.FloatTensor)

# model parameter ì„¤ì •
W = torch.zeros((8,1), requires_grad = True)
b = torch.zeros(1, requires_grad = True)

## hyper parameter ì„¤ì •
lr = 0.0001
num_epochs = 50000
batch_size = 30

# linear Regression model ìƒì„±
def lin_model(X, W, b): 
    return torch.matmul(X, W) + b

# loss í•¨ìˆ˜ ìƒì„±
def loss(y_hat, y):  
    return (y_hat - y.reshape(y_hat.shape))**2 / 2

# optimization algorithm ì •ì˜. í•™ìŠµ
def sgd(W, b, lr, batch_size):  
    with torch.no_grad():
        W -= lr * W.grad / batch_size         
        W.grad.zero_()                        
        
        b -= lr * b.grad / batch_size          
        b.grad.zero_()      
```  


ğŸ”¨ ì´ë ‡ê²Œ í•´ì„œ ë°ì´í„°ë¥¼ ì½ê³ , train_set(X)ì™€ label(y)ë¡œ ë‚˜ëˆˆ ë’¤ì— ê° ëª¨ë¸ê³¼ íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•´ì£¼ì—ˆë‹¤. ì´ì œëŠ” ìœ„ì—ì„œì˜ <a>CustomDataset( )</a>ì„ ì‚¬ìš©í•´ì„œ ì»¤ìŠ¤í…€ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì.  

```py
class CustomDataset(Dataset):
    def __init__(self, data):
        self.features = X            # train_set
        self.labels = y              # labels
        
    def __len__(self):
        return len(self.features)
    
    def __getitem__(self, idx):
        features = torch.FloatTensor(self.features[idx])
        labels = torch.FloatTensor(self.labels[idx])
        return features, labels

# ì»¤ìŠ¤í…€ë°ì´í„°(d) ì´ë¦„ : dataset    
dataset = CustomDataset(d)           

# dataloader : ì»¤ìŠ¤í…€ë°ì´í„°ë¥¼ ëœë¤í•˜ê²Œ ì„ì–´ batch_size ë§Œí¼ ê°€ì ¸ì˜´
dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True)
```  

ğŸ”¨ ì œëŒ€ë¡œ ê°€ì ¸ì™”ëŠ”ì§€ í™•ì¸í•´ë³´ì. ë§Œì•½ ì»¤ìŠ¤í…€ë°ì´í„° datasetì„ <a>batch_size</a> ë§Œí¼ ì œëŒ€ë¡œ ì˜ë¼ì„œ ê°€ì ¸ì™”ë‹¤ë©´ ì´ ë°ì´í„°ì˜ ê¸¸ì´ê°€ 314ì´ê³  batch_sizeëŠ” 30ì´ë¯€ë¡œ dataloaderì˜ ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ëŠ” 14ì˜ ê¸¸ì´ë¥¼ ê°€ì ¸ì•¼ í• ê²ƒì´ë‹¤.  

```py
i = 0
for batch_features, batch_labels in dataloader:
    print(i, '.\t', 'features: ', batch_features.shape, '\n\t', 
          'labels: ', batch_labels.shape, '\n')
    i += 1
```
```
>>
0 .	 features:  torch.Size([30, 8]) 
	 labels:  torch.Size([30]) 

1 .	 features:  torch.Size([30, 8]) 
	 labels:  torch.Size([30]) 

2 .	 features:  torch.Size([30, 8]) 
	 labels:  torch.Size([30]) 

3 .	 features:  torch.Size([30, 8]) 
	 labels:  torch.Size([30]) 

4 .	 features:  torch.Size([30, 8]) 
	 labels:  torch.Size([30]) 

5 .	 features:  torch.Size([30, 8]) 
	 labels:  torch.Size([30]) 

6 .	 features:  torch.Size([30, 8]) 
	 labels:  torch.Size([30]) 

7 .	 features:  torch.Size([30, 8]) 
	 labels:  torch.Size([30]) 

8 .	 features:  torch.Size([30, 8]) 
	 labels:  torch.Size([30]) 

9 .	 features:  torch.Size([30, 8]) 
	 labels:  torch.Size([30]) 

10 .     features:  torch.Size([14, 8]) 
	 labels:  torch.Size([14]) 
```  

ì•„ì£¼ ê¸°ê¹”ë‚˜ê²Œ ê°€ì ¸ì™”ë‹¤ğŸ˜¤ğŸ˜¤!! ì„±ê³µ!!  

ì´ì œëŠ” ê·¸ëƒ¥ forë¬¸ì—ì„œ í•™ìŠµë§Œ ì‹œì¼œì£¼ë©´ ëœë‹¤.  

```py
for epoch in range(num_epochs):
    for batch_features, batch_labels in dataloader:
        l = loss(lin_model(batch_features, W, b), batch_labels)  
        l.sum().backward()
        sgd(W, b, lr, batch_size)

    with torch.no_grad():                              
        train_l = loss(lin_model(X, W, b), y)  
        if epoch%1000==0:
            print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')
```
```
>>
epoch 1, loss 38003.773438
epoch 1001, loss 19245.431641
epoch 2001, loss 18821.029297
epoch 3001, loss 18648.062500
epoch 4001, loss 18526.097656
epoch 5001, loss 18416.160156
epoch 6001, loss 18331.574219
epoch 7001, loss 18309.513672
epoch 8001, loss 18262.779297
epoch 9001, loss 18163.675781

. . .

epoch 90001, loss 17740.068359
epoch 91001, loss 17673.435547
epoch 92001, loss 17668.839844
epoch 93001, loss 17686.435547
epoch 94001, loss 17681.234375
epoch 95001, loss 17723.623047
epoch 96001, loss 17675.238281
epoch 97001, loss 17684.761719
epoch 98001, loss 17671.396484
epoch 99001, loss 17670.376953
```  
```py
with torch.no_grad():
    y_hat = lin_model(X, W, b)
    train_l = loss(y_hat, y)
    print(f'average loss: {float(train_l.mean()):f}')

plt.figure(dpi=100)
plt.scatter(y,y_hat,2)
plt.scatter(np.arange(0,1200,10),np.arange(0,1200,10),1)
plt.grid('on')
plt.xlabel('real value (y)')

plt.ylabel('prediction (y_hat)')
plt.title(f'final loss {float(train_l.mean()):f}')
plt.show()

print('W:',W.detach())
print('b:',b.detach())
```
```
>> average loss: 17668.511719
```  

<p align="center"><img src="https://user-images.githubusercontent.com/65170165/161427606-f25a81b6-d127-43cb-b61e-58ee4728f3d8.png" width="600" /></p>  

```
>>
W: tensor([[ 21.0286],
        [ -5.6660],
        [ 11.9505],
        [-26.1676],
        [  0.5967],
        [ -0.3037],
        [ 10.0532],
        [ 48.4699]])
b: tensor([177.4695])
```  
* * *
ğŸ”¨ ì´ë ‡ê²Œ í•´ì„œ íŒŒì´í† ì¹˜ì˜ ëª¨ë“ˆì„ ì‚¬ìš©í•œ ì»¤ìŠ¤í…€ë°ì´í„°ì…‹ì„ ë§Œë“¤ê³ , ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì„±ê³µí–ˆë‹¤. ì§ì ‘ êµ¬í˜„í•´ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ê²ƒì´ ì›í•˜ëŠ” ë°ì´í„°ì˜ í˜•íƒœì— ë”ìš± ì˜ ë§ê³  ì—ëŸ¬ê°€ ìƒê¸¸ ê°€ëŠ¥ì„±ë„ ì ì„ ìˆ˜ ìˆì§€ë§Œ, ê·¸ í˜•íƒœê°€ íŠ¹ë³„íˆ ìƒì†Œí•œ ê²½ìš°ê°€ ì•„ë‹ˆë¼ë©´ ì´ë ‡ê²Œ ë§Œë“¤ì–´ë‘” ì˜¤í”ˆì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë„ íš¨ìœ¨ì ì¸ ë°©ë²•ì¼ ìˆ˜ ìˆë‹¤ê³  ìƒê°í•œë‹¤.  

ğŸ”¨ ë‹¤ìŒ ë¨¸ì‹ ëŸ¬ë‹ í¬ìŠ¤íŒ…ì—ì„œëŠ” softmax ë¥¼ í†µí•œ í•™ìŠµì„ ë‹¤ë¤„ë³¼ ê²ƒì´ë‹¤.
