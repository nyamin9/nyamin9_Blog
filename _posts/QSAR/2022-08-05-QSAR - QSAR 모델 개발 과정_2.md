---
title : "💊 QSAR(5) - QSAR 모델 개발 과정_2"

categories:
    - QSAR
tags:
    - [QSAR, Cheminfomatics, drug, developement, LAIDD]

toc : true
toc_sticky : true 
use_math : true  

date: 2022-08-05
last_modified_at: 2022-08-05 
---  
* * *  

💊 저번 포스팅에서는 QSAR 모델을 사용하는 목적과, 그 세부적인 과정들에 대해 살펴보았다. 정리하자면 <a>여러 단계를 거쳐 원하는 target에 binding하는 drug를 찾아내고, 그 drug의 activity를 예측하는 것</a>이 우리가 QSAR 모델을 사용하는 목적이다.  

💊 머신러닝이나 딥러닝을 배운적이 있다면 알겠지만, 만든 모델을 사용할지 결정하기 위해서는 해당 모델을 평가하는 단계가 필요하다. 이번 포스팅에서는 이 부분에 대해서 알아보도록 하자🙃.  

* * *  

## 6. Model validation  

- <a>training dataset</a>을 통해 Model을 완전히 optimize했다고 해서 이 model이 <a>완전히 새로운 molecule</a>에 대해서도 완벽한 prediction accuracy를 가질 것이라 보장할 수는 없다.  
- 즉, training dataset에 대한 model의 적합도는 새로운 화합물에 대한 prediction accuracy를 나타내는 좋은 지표가 아니다.<br>  

- 예를 들어 training dataset의 모든 데이터를 설명하기 위해 지나치게 복잡한 차원의 model을 만든다면 이는 training dataset에 대해서는 완벽히 설명이 가능하겠지만 오히려 <a>overfitting</a>을 일으켜 데이터에 대한 generalization을 보장할 수 없다.  
- 따라서, <a>model의 complexity가 높다고 해서 무조건 좋은 것은 아니다!!</a><br>  

<p align="center"><img src="https://user-images.githubusercontent.com/65170165/183012983-005628a2-1b60-49ba-a65d-070e6a52e7e3.png" width="900" /></p><br>  

👉 위의 그림에서 각각의 point가 training data를 의미한다. 그리고 이 데이터를 설명하기 위해 점점 model complexity를 늘리고 있다. Sixth Order의 그림의 경우에는 모든 training data를 설명하기 위해 상당히 복잡한 모델을 사용하고 있지만, 앞서 설명한 대로 이 경우 새로운 data에 대해서 generalization이 굉장히 힘들기 때문에 좋은 model이라고 말할 수는 없다😨😨. 오히려 overfitting이 예상되는 경우이다.  

* * *  

## 7. External Test Sets and Cross Validation  

- Dataset은 보통 Training set, Test set으로 나눠지는데, 데이터의 수가 충분한 경우에는 Test set을 Validation set과 Test set으로 나눠서 모델의 검증에 사용하기도 한다.  
- 이때 Validation set에서는 model의 <a>hyperparameter</a>를 최적화한다.<br>  

<p align="center"><img src="https://user-images.githubusercontent.com/65170165/183015152-85fbadd5-b5fa-4b0a-91a3-fb8d12646ffa.png" width="500" /></p><br>

- 위의 그림처럼, 가장 중요한 점은 Model의 학습은 <a>Test set에 대한 Error가 최소화되는 지점</a>까지만 해야 한다는 것이다.<br>  

- 최종적인 Model의 Accuray는 training set과는 완전히 독립적인 Test set에 대해서 구해진다.<br>  

* * *  

## 8. Data Splitting  

💊 Dataset을 train, validation, test set으로 나누는 여러 가지 방법이 존재한다. 아래 그림을 보면서 이해하면 좋을 것 같다.<br>  

<p align="center"><img src="https://user-images.githubusercontent.com/65170165/183015448-c68d08a3-9316-4913-974f-71da916ad2e0.png" width="600" /></p><br>  

- <a>Random</a> : 랜덤하게 나누는 방법<br>  
  
- <a>Cluster-based (scaffold split)</a> : Chemical Similarity를 기준으로 원래 dataset에 대해 clusetring 하고, 형성된 각각의 군집을 training, validation, test set으로 사용하는 방법.<br>  
    - compound의 structure가 달라진 경우의 예측 성능을 확인하기 위해 사용.  
    - 학습에 쓰인 데이터와 평가에 사용하는 데이터의 구조가 대부분 완전히 다르기 때문에 prediction accuracy는 낮음<br>  


- <a>Stratified</a> : 전체 dataset에서의 각 class의 비율과 나눠진 각각의 set에서의 각 class의 비율이 동일하도록 나누는 방법<br>  

- <a>Temporal</a> : 년도를 기준으로 나누는 방법 - Chembl20 (training), Chembl21 (test)<br>  

* * *  

## 9. Cross Validation  

💊 데이터의 수가 충분하지 않아서 training set과 test set을 완전히 구분할 수 없는 경우 사용함.<br>  

- <a>Leave-one-out</a> : 하나의 object만 남겨두고 나머지는 training set으로 사용하는 방법.<br>  
- <a>leave-cluster-out</a> : scaffold split과 유사한 방법<br>  

💊 대부분의 경우 위의 두 방법보다는 <a>n-fold cross validation</a>를 사용한다. 아래 그림이 설명이 잘 되어 있으니 참고하면 좋을 것 같다.<br>  

<p align="center"><img src="https://user-images.githubusercontent.com/65170165/183016644-e340b7c9-782d-4026-80ab-b940b04bfeb8.png" width="800" /></p><br>  

- <a>n-fold cross validation</a> : 원본 데이터를 n등분해서<br>  

    - 첫 번째 모델은 첫 번째 fold를 test set으로 사용하고 나머지 fold로 학습을 진행.  
    - 두 번째 모델은 두 번째 fold를 test set으로 사용하고 나머지 fold로 학습을 진행....  
    - 그 결과 <a>n개의 모델</a>이 만들어지며, 이 중에서 <a>가장 성능이 좋은 모델</a>을 final model로 선택.<br>  

* * *  

## 10. model의 성능에 영향을 주는 issues  

💊 이번 절에서는 우리가 QSAR model을 만드는 과정에서 그 성능에 영향을 미칠 수 있는 주요 몇가지 issue에 대해서 알아볼 것이다.  

* * *  

### 🚩 10.1. Data Size  

- compound의 수는 너무 적거나 많아서는 안됨.  
- 데이터 크기의 <a>upper limit</a>는 모델 구축에 사용하는 컴퓨터와 시간에 대해 영향을 받을 수 있으나, 최근에는 하드웨어와 소프트웨어의 발달로 그 영향이 미미함.<br>  


- 데이터셋에 많은 compound가 포함될수록<br>  
    - 다양한 subset of compounds를 선택 가능.  
    - 데이터셋을 Clustering하고 각 Cluster에 대해 개별적으로 다양한 모델 구축.  
    - classification / category data 에서 특정 compound가 소수의 activity class 혹은 category에 속하는 경우 이러한 compound를 model 개발과정에서 배제해도 문제가 없음.<br>  

* * *

### 🚩 10.2. Lower limit  

- 위에서 말했듯이 데이터 사이즈의 upper limit은 큰 문제가 되지 않으나 <A>lower limit</a> 의 경우는 너무 작은 경우 <a>correlation</a>과 <a>overfitting</a> 문제가 발생함.<br>  

- <b>Continuous response variable (activity)</b><br>  
    - training set의 compounds 수는 적어도 20개여야 함.  
    - 대략 10개의 compound가 각각의 test set과 external evaluation set에 있어야 함.  
    - 즉, <A>최소 40개의 compound dataset</a> 이 있어야 한다.<br>  

- <b>Classification or category response variable</b><br>  
    - training set의 compounds 수는 각 class마다 적어도 10개여야 함.  
    - test set과 external evaluation set은 각 class마다 적어도 5개의 compound를 포함해야 함.  
    - 즉, <A>하나의 class 당 최소 20개의 compound dataset</a> 이 있어야 한다.<br>  

* * *  

### 🚩 10.3. Activity Values  

- <b>Continuous response variable</b><br>  
    - Total range of activities (데이터의 최댓값 – 최솟값)가 experimental error보다 최소 5배 이상 커야 함. 즉, 데이터가 균등하게 퍼져있어야 함.<br>  

    - 두 연속된 activity 값 사이에 Total range of activities의 10%~15% 를 넘을 만큼의 차이가 없어야 함. 즉, outlier가 없을수록 좋음.<br>  

- <b>Classification or category QSAR</b><br>  
    - 하나의 class 당 최소 20개의 compound dataset이 있어야 함.<br>  
    - 모든 class 또는 category에서 cmopound의 수는 거의 같아야 함.  
        - positve : 100 / negative : 100<br>  

* * *  


## 11. Assessing Model Performance  

- 모델의 성능을 계산하기 위한 방법들<br>  

- <b>Regression Problems</b><br>  
   
    - MAE, MSE (Mean Squared Error), RMSE  
    - Pearson correlation coefficient : 상관관계 분석  
    - Spearman Rank Correlation : 순위 분석<br>  

- <b>Classification Problems</b><br>  

    - Classification Accuracy  
    - Precision, Recall, F1 score  
    - ROC Curve, AUC, PRC<br>  

* * *  

## 12. Applicability domain  

💊 QSAR 모델은 <a>training set의 structure로 표현되는 compound에 대한 prediction만 제공</a> 가능하다. 따라서 training set에 속하지 않는 데이터들을 사용할 수 있는 방법이 필요하다.<br>  

- <b>Distance-to-model-based metrics</b><br>  
    - training set에 있는 compound와 test set에 있는 compound 사이의 <a>distance</a> 를 정량화.<br>  

- <b>Local error methods</b><br>  
    - test set에 있는 compound와 유사하며 그 측정값을 알고 있는 compound의 prediction error에 따라, <a>test compound prediction의 신뢰성을 추정.</a><br>  

- <b>Bagging methods</b><br>  
    - 개별 model의 예측 분산을 <A>앙상블 전체에 걸쳐 사용</a>하여 prediction의 신뢰성을 나타냄.<br>  

- <b>Sensitivity-based methods</b><br>  
    - model의 prediction에 어떤 영향을 미치는지 확인하기 위해 <a>test compound의 input descriptors를 변형</a> 해보는 것.  
    - 예를 들어 model의 구조를 살짝 바꿔보는 방법이 있음.<br>  

* * *  

## 13. Predictive QSAR models  

💊 앞서 다룬 내용들을 요약하면 다음과 같다.<br>  

Chemical Dataset  
▶ <a>Curated Dataset</a>   
▶ Descriptors Generation  
▶ Split into Training, Test, External Validation sets  
▶ Machine Learning Techniques  
▶ Selection of Models with High Internal & External Accuracy  
▶ Assessment of Applicability Domain  
▶ <a>Predictive QSAR models</a><br>  

위의 파이프라인을 따라서 최종 QSAR 모델을 정하게 되는데, <a>Curated Dataset</a>과 <a>Predictive QSAR models</a>는 이번 절에서 간단하게 다룰 것이다.<br>  

* * *

### 🚩 13.1. Curated Dataset  

💊 머신러닝을 위해 우리는 분자의 구조를 descriptor vector의 형태로 변환해야 한다. 이에 앞서 진행되는, 원래의 Chemical Dataset을 Curated Dataset으로 변경하는 과정을 알아보도록 하자.<br>  

Chemical Dataset  
▶ Removal of mixtures, inorganics (즉 organometallics)  
▶ Structure conversion. Cleaning / removal of salts  
▶ Normalization of specific chemotypes  
▶ Treatment of automatic forms  
▶ Analysis / Removal of structural duplicates  
▶ Manual Inspection  
▶ Curated Dataset<br>  

💊 우리가 보통 다루는 molecule data는 SMILES 형태인데, 이는 이미 curated dataset의 형태이다. 앞으로 다룰 PaDEL Descriptor에서는 이미 이 과정을 모두 거친 형태이므로, 개략적인 개념만 알고 가도 좋을 것 같다.  

* * *  

### 🚩 13.2. Predictive QSAR models  

💊 QSAR의 결과로 나오는 최종 모델을 고르는 과정을 의미한다. 지난 내용들의 요약과 그 흐름으로 이해하도록 하자🙃.<br>  

- 우리가 가지고 있는 데이터셋을 머신러닝 모델이 인식할 수 있는 형태로 바꾸고, 학습을 진행하여 모델을 업데이트한다. 이후 가장 성능이 좋게 나온 모델을 최종 모델로 선택하고, training set에 속하지 않는 데이터를 사용할 수 있도록 적절한 Applicability Domain 방법을 찾아 결과를 평가한다. 이렇게 최종적인 평가단계까지 성능이 괜찮으면 해당 모델을 최종 QSAR 모델로 선정한다.  

* * *  

💊 이렇게 해서 QSAR을 통해 drug를 발굴하는 방법을 배웠다. 저번 포스팅에서는 QSAR model을 만들기 위한 세부적인 과정을, 이번 포스팅에서는 만들어진 model의 평가를 통해 제일 좋은 model을 선택하는 법과 다양한 데이터를 적용하는 파이프라인에 대해서 알아보았다. 여기까지의 과정과 각각의 단계를 하는 목적을 위주로 이해하면 앞으로 다룰 내용들에 있어서 헷갈리는 부분은 없을 것이라 생각한다.  

💊 나도 강의를 들으면서 공부를 하고, 정리하면서 동시에 블로그에 포스팅을 하는 중이기 때문에 생각보다 시간이 많이 드는 것 같다. 포스팅을 하나 하고 나면 다른 강의를 듣고 다시 정리를 하면서 글을 올리는 입장이기 때문에, 시간상으로나 내용 상으로나 조금 아쉽다는 생각이 든다😥😥. 한 건 없지만 이것저것 하다 보니 어느새 방학도 한달이 채 남지 않았다. 좀 더 열심히 힘내서 해봐야겠다🏃‍♂️🏃‍♂️.  

* * *  

💡위 포스팅은 LAIDD에 업로드된 KAIST 김동섭 교수님의 [QSAR 모델 개발 과정](https://www.laidd.org/my/lesson/topic/28/lecture/238?no=1) 강의 내용을 바탕으로 함을 밝힙니다.